Counting Big-O complexity involves understanding how the number of operations grows with respect to the input size. Here's a step-by-step guide to determining Big-O complexity with Java examples:

### Step-by-Step Guide to Counting Big-O Complexity

1. **Identify the input size (n).**
2. **Analyze each part of the code.**
3. **Sum up the operations.**
4. **Determine the dominant term.**
5. **Express the complexity in Big-O notation.**

Let's go through these steps with a few examples.

### Example 1: Finding the Maximum Element in an Array

**Code:**

```java
public class FindMax {
    public static void main(String[] args) {
        int[] numbers = {3, 5, 7, 2, 8};
        int max = findMax(numbers);
        System.out.println("The maximum value is: " + max);
    }

    public static int findMax(int[] numbers) {
        int max = numbers[0]; // O(1)
        for (int num : numbers) { // O(n)
            if (num > max) { // O(1)
                max = num; // O(1)
            }
        }
        return max; // O(1)
    }
}
```

**Analysis:**
- `int max = numbers[0];` is a constant-time operation: **O(1)**.
- The `for` loop runs `n` times, where `n` is the length of the array: **O(n)**.
- Inside the loop, `if (num > max)` and `max = num` are constant-time operations: **O(1)** each.

**Total Complexity:**
- The dominant term is the loop which runs `n` times.
- Therefore, the Big-O complexity is **O(n)**.

### Example 2: Binary Search

**Code:**

```java
public class BinarySearch {
    public static void main(String[] args) {
        int[] numbers = {2, 3, 5, 7, 8};
        int target = 7;
        int index = binarySearch(numbers, target);
        System.out.println("Element found at index: " + index);
    }

    public static int binarySearch(int[] arr, int target) {
        int left = 0, right = arr.length - 1; // O(1)
        while (left <= right) { // O(log n)
            int mid = left + (right - left) / 2; // O(1)
            if (arr[mid] == target) // O(1)
                return mid;
            if (arr[mid] < target) // O(1)
                left = mid + 1; // O(1)
            else
                right = mid - 1; // O(1)
        }
        return -1; // O(1)
    }
}
```

**Analysis:**
- Initialization of `left` and `right` is constant-time: **O(1)**.
- The `while` loop divides the search space in half each iteration, leading to a logarithmic number of iterations: **O(log n)**.
- Operations inside the loop (calculating `mid`, comparisons, and assignments) are constant-time: **O(1)** each.

**Total Complexity:**
- The dominant term is the logarithmic number of iterations.
- Therefore, the Big-O complexity is **O(log n)**.

### Example 3: Bubble Sort

**Code:**

```java
public class BubbleSort {
    public static void main(String[] args) {
        int[] numbers = {3, 5, 7, 2, 8};
        bubbleSort(numbers);
        System.out.println("Sorted array: " + Arrays.toString(numbers));
    }

    public static void bubbleSort(int[] arr) {
        int n = arr.length; // O(1)
        for (int i = 0; i < n - 1; i++) { // O(n)
            for (int j = 0; j < n - i - 1; j++) { // O(n)
                if (arr[j] > arr[j + 1]) { // O(1)
                    // Swap arr[j] and arr[j + 1]
                    int temp = arr[j]; // O(1)
                    arr[j] = arr[j + 1]; // O(1)
                    arr[j + 1] = temp; // O(1)
                }
            }
        }
    }
}
```

**Analysis:**
- Initialization of `n` is constant-time: **O(1)**.
- The outer `for` loop runs `n` times: **O(n)**.
- The inner `for` loop also runs `n` times in the worst case: **O(n)**.
- Operations inside the inner loop (comparison and swap) are constant-time: **O(1)** each.

**Total Complexity:**
- The nested loops result in a quadratic time complexity: **O(n) * O(n) = O(n^2)**.

### Example 4: Fibonacci Sequence (Naive Recursive Approach)

**Code:**

```java
public class Fibonacci {
    public static void main(String[] args) {
        int n = 5;
        int result = fibonacci(n);
        System.out.println("Fibonacci number at position " + n + " is: " + result);
    }

    public static int fibonacci(int n) {
        if (n <= 1) return n; // O(1)
        return fibonacci(n - 1) + fibonacci(n - 2); // O(2^n)
    }
}
```

**Analysis:**
- The base case is constant-time: **O(1)**.
- Each call to `fibonacci` results in two more calls, leading to an exponential number of calls.

**Total Complexity:**
- The recursive calls lead to an exponential growth in the number of operations: **O(2^n)**.

### Key Points

1. **Identify the most time-consuming parts of the code.**
2. **Sum up the complexities of all parts.**
3. **Focus on the dominant term, ignoring lower-order terms and constants.**
4. **Express the complexity using Big-O notation.**

Understanding how to count Big-O complexity helps in analyzing and optimizing algorithms for better performance.
